{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6093a2a-e6ed-48fd-906d-e82de29728eb",
   "metadata": {},
   "source": [
    "https://www.machinio.com/\n",
    "\n",
    "### Objectives\n",
    "Scrape this data:\n",
    "\n",
    "<li>Make - Combilift or AisleMaster</li>\n",
    "<li>Model</li>\n",
    "<li>Capacity</li> \n",
    "<li>Lift Height</li>\n",
    "<li>Hours</li>\n",
    "<li>Engine Type</li>\n",
    "<li>Year</li>\n",
    "<li>Price</li>\n",
    "<li>Seller name</li>\n",
    "<li>Seller location</li>\n",
    "<li>Equipment location</li>\n",
    "<li>serial number</li>\n",
    "<li>link to ad</li>\n",
    "<li>Auction yes/no</li>\n",
    "<li>Auction date</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e2abd8-8eba-4135-8943-e79d60372724",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f85e7b33-4011-4039-bf32-1e2acab97d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "# from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import dataframe_image as dfi\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e1617-046d-4c38-962b-c8b7be09a0a3",
   "metadata": {},
   "source": [
    "### Create First Request (list by search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6dcf88a7-5342-4c72-96d8-7603f8265e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH\n"
     ]
    }
   ],
   "source": [
    "# list pages (search = 'aislemaster')\n",
    "## title, link, manufacturer, price, location, status, desc, stars, auction\n",
    "\n",
    "title, links, manufacture, price, location, status, desc, stars, auction = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "op.add_argument(\"--headless=new\")\n",
    "op.add_experimental_option(\n",
    "    \"excludeSwitches\", ['enable-automation'])\n",
    "\n",
    "op.add_argument(\n",
    "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\")\n",
    "# op.add_argument(\"--remote-debugging-port=9222\")\n",
    "\n",
    "driver = webdriver.Chrome(options=op)  \n",
    "driver.get('https://www.machinio.com/');\n",
    "time.sleep(1) # Let the user actually see something!\n",
    "\n",
    "login_btn = driver.find_element(By.NAME, \"search\")\n",
    "\n",
    "# comment or uncomment below to change search key\n",
    "# login_btn.send_keys(\"aislemaster\")\n",
    "login_btn.send_keys(\"combilift\")\n",
    "\n",
    "login_btn = driver.find_element(By.ID, \"search-submit\")\n",
    "login_btn.click()\n",
    "time.sleep(1) # Let the user actually see something!\n",
    "\n",
    "# total page number\n",
    "page_num = driver.find_element(By.ID, 'search-results')\n",
    "page_num = int(page_num.get_attribute('data-total-pages'))\n",
    "\n",
    "\n",
    "for i in range(1, page_num+1, 1):\n",
    "    page_class = \"div[data-page-number='{}']\".format( i )\n",
    "    page_class = driver.find_element(By.CSS_SELECTOR, page_class)\n",
    "\n",
    "    pages = page_class.find_element(By.CLASS_NAME, 'offer-listing__list') \n",
    "    daftar = pages.find_elements(By.CLASS_NAME, 'c-card.c-card--link.c-listing-card')\n",
    "    \n",
    "    for j in daftar:\n",
    "        new_tab = None # auction check\n",
    "        # check post available\n",
    "        try:\n",
    "            auctioncek = j.find_element(By.CLASS_NAME, 'lead-wizard-modal-open-button-container').get_attribute('data-contactable') # post availabled\n",
    "        except:\n",
    "            auctioncek = 'true'\n",
    "            new_tab = True\n",
    "        \n",
    "        if auctioncek == 'true':\n",
    "            if new_tab:\n",
    "                auction.append('Yes')\n",
    "            else:\n",
    "                auction.append('No')\n",
    "            try: \n",
    "                title.append(j.find_element(By.CSS_SELECTOR, \"h4\").text)\n",
    "            except: title.append('-')\n",
    "            try: \n",
    "                links.append(j.find_element(By.CSS_SELECTOR, \"h4 a\").get_attribute('href'))\n",
    "            except: links.append('-')\n",
    "            try: \n",
    "                manufacture.append(j.find_element(By.CLASS_NAME, \"c-listing-card__spec-value\").text)\n",
    "            except: manufacture.append('-')\n",
    "            try: \n",
    "                price.append(j.find_element(By.CLASS_NAME, \"c-listing-card__price\").text)\n",
    "            except: price.append('-')\n",
    "            try: \n",
    "                location.append(j.find_element(By.CLASS_NAME, \"c-card__text-light.c-listing-card__location\").text)\n",
    "            except: location.append('-')\n",
    "            try: \n",
    "                status.append(j.find_element(By.CLASS_NAME, \"c-listing-card__spec-used\").text)\n",
    "            except: status.append('-')\n",
    "            try: \n",
    "                desc.append(j.find_element(By.CLASS_NAME, \"c-card__text\").text)\n",
    "            except: desc.append('-')\n",
    "            try:\n",
    "                stars.append(j.get_attribute('data-star-count'))\n",
    "            except:\n",
    "                stars.append('-')\n",
    "                \n",
    "    if i == page_num:\n",
    "        break\n",
    "    else:\n",
    "        driver.find_element(By.CLASS_NAME, 'c-pagination__item.icon-chevron-right-solid').click()\n",
    "        time.sleep(5)\n",
    "\n",
    "print('FINISH')\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d5003-14f8-4bbb-b7ab-320a13e60718",
   "metadata": {},
   "source": [
    "### Save DataFrame to Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fe5ab631-c590-4f9b-9c2d-0383c95cd514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'title': title, 'links': links, 'manufacture': manufacture, 'price': price, 'location': location, \n",
    "             'status': status, 'desc': desc, 'ratings': stars, 'auction': auction})\n",
    "\n",
    "# comment or uncomment this to save different name pickel file per key search\n",
    "# df1.to_pickle('./aisle_list1.pkl')\n",
    "df1.to_pickle('./combilift_list1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "999df51f-38aa-42cc-beb1-66569f76e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/dataframe-image/\n",
    "\n",
    "df = pd.read_pickle('aisle_merged1.pkl')\n",
    "\n",
    "dfi.export(df, 'df1_aisle.png', max_rows=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec4e3ae-b3fd-42d4-9fad-bc2006cbe43a",
   "metadata": {},
   "source": [
    "### Create Function to Scrape Detail Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "590a52a9-7313-436d-a546-8b0f7512e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function detail pages\n",
    "def get_details(driver1, key_search):\n",
    "    model = None; cap = None; lh = None; hours = None; ep = None; year = None; price = None; sell_loc = None; eq_loc = None; sn = None;\n",
    "    # get description\n",
    "    try:\n",
    "        desc = driver1.find_element(By.ID, \"listing-show-description-body\").text.split('\\n')\n",
    "    except: desc = ''\n",
    "    \n",
    "    \n",
    "    # find model\n",
    "    try:\n",
    "        model = driver1.find_element(By.XPATH, \"//*[contains(text(), 'Model:')]/following-sibling::dd\").text\n",
    "    except:\n",
    "        try:\n",
    "            for aih in desc:\n",
    "                if re.search('model', aih, re.IGNORECASE):\n",
    "                    model = aih\n",
    "            if not model:\n",
    "                model = driver1.find_element(By.TAG_NAME, 'h1').text\n",
    "                model = re.split(key_search, model, flags=re.IGNORECASE)[1].split(' ')[1]\n",
    "        except:model='-'\n",
    "    \n",
    "    \n",
    "    # find capacity\n",
    "    try:\n",
    "        cap = driver1.find_element(By.XPATH, \"//*[contains(text(), 'Capacity:') or contains(text(), 'capacity:')]/following-sibling::dd\").text\n",
    "    except:\n",
    "        try:\n",
    "            for aih in desc:\n",
    "                if re.search('capacity', aih, re.IGNORECASE):\n",
    "                    cap = aih\n",
    "        except:cap='-'\n",
    "            \n",
    "    \n",
    "    # find lift height\n",
    "    try:\n",
    "        lh = driver1.find_element(By.XPATH, \"//*[contains(text(), 'Lift height:') or contains(text(), 'Lift Height:')]/following-sibling::dd\").text\n",
    "    except:\n",
    "        try:\n",
    "            for aih in desc:\n",
    "                if re.search('lift height', aih, re.IGNORECASE):\n",
    "                    lh = aih\n",
    "        except:lh='-'\n",
    "            \n",
    "    \n",
    "    # find hours\n",
    "    try:\n",
    "        hours = driver1.find_element(By.XPATH, \"//*[contains(text(), 'Hours:') or contains(text(), 'Hrs.:')]/following-sibling::dd\").text\n",
    "    except:\n",
    "        try:\n",
    "            for aih in desc:\n",
    "                if re.search('hours', aih, re.IGNORECASE):\n",
    "                    hours = aih\n",
    "        except:hours='-'\n",
    "    \n",
    "    \n",
    "    # find engine type\n",
    "    try:\n",
    "        ep = driver1.find_element(By.XPATH, \"//*[contains(text(), 'Fuel type:') or contains(text(), 'Power:') or contains(text(), 'Fuel:') or contains(text(), 'Propulsion type:')]/following-sibling::dd\").text\n",
    "    except:\n",
    "        try:\n",
    "            for aih in desc:\n",
    "                if re.search('fuel type', aih, re.IGNORECASE):\n",
    "                    ep = aih\n",
    "                elif re.search('power', aih, re.IGNORECASE):\n",
    "                    ep = aih\n",
    "                elif re.search('propulsion type', aih, re.IGNORECASE):\n",
    "                    ep = aih\n",
    "                elif re.search('fuel', aih, re.IGNORECASE):\n",
    "                    ep = aih\n",
    "        except:ep='-'\n",
    "    \n",
    "    \n",
    "    # find year\n",
    "    try:\n",
    "        year = driver1.find_element(By.XPATH, \"//*[contains(text(), 'Year:')]/following-sibling::dd\").text\n",
    "    except:\n",
    "        try:\n",
    "            for aih in desc:\n",
    "                if re.search('year', aih, re.IGNORECASE):\n",
    "                    year = aih\n",
    "        except:year='-'\n",
    "    \n",
    "    \n",
    "    # find price\n",
    "    try:\n",
    "        price = driver1.find_element(By.XPATH, \"//*[contains(text(), 'Price:')]/following-sibling::dd\").text\n",
    "    except:\n",
    "        try:\n",
    "            for aih in desc:\n",
    "                if re.search('price', aih, re.IGNORECASE):\n",
    "                    year = aih\n",
    "        except:price='-'\n",
    "            \n",
    "    \n",
    "    # find seller and equipment location\n",
    "    try:\n",
    "        location = driver1.find_element(By.XPATH, \"//*[contains(text(), 'Location:')]/following-sibling::dd\").text\n",
    "        sell_loc = location\n",
    "        eq_loc = location\n",
    "    except:\n",
    "        try:\n",
    "            location = driver1.find_element(By.TAG_NAME, 'h1').text\n",
    "            location = location.split(' in ')[1]\n",
    "            sell_loc = location\n",
    "            eq_loc = location\n",
    "        except:\n",
    "            sell_loc = '-'\n",
    "            eq_loc = '-'\n",
    "    \n",
    "    \n",
    "    # find serial number\n",
    "    try:\n",
    "        sn = driver1.find_element(By.XPATH, \"//*[contains(text(), 'Serial number:')]/following-sibling::dd\").text\n",
    "    except:\n",
    "        try:\n",
    "            for aih in desc:\n",
    "                if re.search('serial number', aih, re.IGNORECASE):\n",
    "                    sn = aih\n",
    "        except:sn='-'\n",
    "\n",
    "    data = {'model': model,\n",
    "                    'cap': cap,\n",
    "                    'lh': lh,\n",
    "                    'hours': hours,\n",
    "                    'ep': ep,\n",
    "                    'year': year,\n",
    "                    'price': price,\n",
    "                    'sell_loc': sell_loc,\n",
    "                    'eq_loc': eq_loc,\n",
    "                    'sn': sn}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d4d53-8b5e-4a84-9d38-2ea490452f0e",
   "metadata": {},
   "source": [
    "### Scrape Detail Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ad420ed0-ee4d-4393-b02d-33c08785191b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH\n"
     ]
    }
   ],
   "source": [
    "# get detail pages\n",
    "data2 = []\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "op.add_argument(\"--headless=new\")\n",
    "op.add_experimental_option(\n",
    "    \"excludeSwitches\", ['enable-automation'])\n",
    "\n",
    "op.add_argument(\n",
    "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=op)  \n",
    "# driver = webdriver.Chrome()  \n",
    "\n",
    "for i in df1.links:\n",
    "    driver.get(i);\n",
    "    time.sleep(1) # Let the user actually see something!\n",
    "\n",
    "    # comment or uncomment this to save different name pickel file per key search\n",
    "    # data = get_details(driver, 'aislemaster')\n",
    "    data = get_details(driver, 'combilift')\n",
    "    \n",
    "    time.sleep(1)\n",
    "    data2.append(data)\n",
    "print('FINISH')\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade9de2-c2a3-4dd6-8c27-91772eb25238",
   "metadata": {},
   "source": [
    "### Merge DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "039d0b6f-788a-4198-b7e4-755c4d0a2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dict to df\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# merge df, get used value\n",
    "df_merged = df1[['title', 'links', 'auction']].copy()\n",
    "df_merged = pd.concat([df_merged, df2], axis=1).reindex(df_merged.index)\n",
    "\n",
    "# renaming columns\n",
    "df_merged.rename(columns={'links': 'link', 'cap': 'capacity', 'lh': 'lift_height', 'ep': 'engine_type', 'sell_loc': 'seller_location',\n",
    "                         'eq_loc': 'equipment_location', 'sn': 'serial_number'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ca31b93e-d4b5-48c2-aa2d-4a07b131faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment or uncomment this to save different name pickel file per key search\n",
    "# df2.to_pickle('./aisle_details1.pkl')\n",
    "# df_merged.to_pickle('./aisle_merged1.pkl')\n",
    "\n",
    "df2.to_pickle('./combilift_details1.pkl')\n",
    "df_merged.to_pickle('./combilift1_merged.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306e365-0041-406d-a041-e71e66067599",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
